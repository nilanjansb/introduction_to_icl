{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7307fbd-574c-4fc6-be47-a05700512127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/abs/2409.17745"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddaaf8-43e8-4f66-8b52-c09c38b83f78",
   "metadata": {},
   "source": [
    "## Import required libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09b6aa-bb60-49f8-9713-f4e7b09b0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import configuration\n",
    "from models.llm_tokenizer import LoadLLM_Model, LoadLLM_Tokenizer\n",
    "from models.llm_generator import LLMGenerator\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afe78d-8b0e-4181-9403-7f431701ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SEEDING FOR GETTING SAME OUTPUT\n",
    "'''\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b2cc2-7684-4535-af3f-8ce617906031",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc9ce7-9868-4a93-8953-c411aaf57a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'dl19'\n",
    "dataset = pt.datasets.get_dataset(configuration.datasets[ds]['name'])\n",
    "topics = dataset.get_topics(configuration.datasets[ds]['topics'])\n",
    "qrels = dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9076b-d6f7-48d8-bb67-6e2267618f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd238277-0865-468a-b14b-cdd037575602",
   "metadata": {},
   "source": [
    "## Load Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6696603-565b-4040-841f-e20dd3136aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(configuration.datasets[ds]['index'], memory=True)\n",
    "meta = index.getMetaIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec5c8b-d664-44e8-b6e6-35b626f3819d",
   "metadata": {},
   "source": [
    "## Initialize the LLM - Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa57aa-fd7e-4db3-97cf-dbf3dd987821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = 'flanxl'\n",
    "model_name = 'zephyr'\n",
    "model = LoadLLM_Model(model_name)\n",
    "tokenizer = LoadLLM_Tokenizer(model_name)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "parameters = {\n",
    "    'device': device,\n",
    "    'model': model,\n",
    "    'tokenizer': tokenizer,\n",
    "    'enc_tokens': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b4ec6-dec4-4db7-ba41-aa59098a0a17",
   "metadata": {},
   "source": [
    "## Get started with zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f28c23-419c-4bcd-8510-4fb5320240ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data = topics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3647e-7411-4942-a43e-7578dc080877",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f2133-2833-4864-b001-304e62328404",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "FIND THE ACTUAL RELEVANT ANSWERS\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4728fde-292f-4eef-b1ea-85600ac0a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data[\"rel_docno\"] = ''\n",
    "working_data[\"text\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27f1a0-5823-44b2-9e52-2ae8225834a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in tqdm(working_data.iterrows(), total=working_data.shape[0]):\n",
    "    qid = row['qid']\n",
    "    # find rel_doc_no\n",
    "    rel_docs = qrels.loc[(qrels['qid']==qid) & (qrels['label']>=2)]\n",
    "    rel_docs = rel_docs.sort_values('label', ascending=False)\n",
    "    rel_doc_id = rel_docs.values[0][1]\n",
    "    working_data.loc[index, 'rel_docno'] = rel_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef797f49-7748-47b7-bada-ea17381c7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in tqdm(working_data.iterrows(), total=working_data.shape[0]):\n",
    "    doc_no = row['rel_docno']\n",
    "    working_data.loc[index, 'text'] = meta.getItem(\"text\", int(doc_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866a490-f4ab-4612-a27e-08b9ce47feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d9adf-a570-4bfc-a01b-d9a267e40458",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ENGINEER THE PROMPT\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c9ed1-5df6-48a7-8d66-ec87efe30cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_prompt = '''\n",
    "    Answer the following query in detail with explanations.\n",
    "    Query: \"{QUERY}\"\n",
    "    Answer:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790c171-b479-41f6-a751-14f2f1a016d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "GENERATE ZERO-SHOT ANSWER FROM THE MODEL\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2bcfe6-2423-4b19-9cfe-7fc9c40ad428",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in tqdm(working_data.iterrows(), total=working_data.shape[0]):\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    prompt = template_prompt.format(QUERY=query)\n",
    "    gen_text = LLMGenerator.generate(model_name, parameters, prompt, gen_mode = True)\n",
    "    if model_name=='zephyr':\n",
    "        llm_output = gen_text.split('\\n')\n",
    "        working_data.loc[index, 'llm_text'] = llm_output[len(llm_output)-1]\n",
    "    else:\n",
    "        working_data.loc[index, 'llm_text'] = gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4d418-968b-49f5-bf46-b69fec601a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee9ff5-fe3c-4754-b9de-bedabbeb9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "EVALUATE THE GENERATED OUTPUT\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e4d97-f5ca-463b-af7c-058a6ff9e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyse answer quality\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "cache_path = os.path.join(os.path.expanduser('~'), 'Documents', 'Nilanjan', 'cache')\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_path\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be2bd1-c60f-455b-8305-47ced0928ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in tqdm(working_data.iterrows(), total=working_data.shape[0]):\n",
    "    text = row['text']\n",
    "    llm_text = row['llm_text']\n",
    "    \n",
    "    embedding_text = model.encode(text)\n",
    "    embedding_llm_text = model.encode(llm_text)\n",
    "    \n",
    "    sim_score = util.pytorch_cos_sim(embedding_text, embedding_llm_text)\n",
    "    sim_score = sim_score.tolist()\n",
    "    sim_score = sim_score[0]\n",
    "\n",
    "    working_data.loc[index, 'sim_score'] = sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676f99d-5a00-4cc4-b3c2-34c9fd14d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3636cdf-b626-4cb2-ad40-9604a7f18a22",
   "metadata": {},
   "source": [
    "## Get started with few-shot ICL prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873d435-ffbf-4a90-9215-c323e6759ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_data = working_data[['qid','query','rel_docno','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86fd67-886b-427a-beee-61e27b1e4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ENGINEER THE PROMPT\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598066e-fa1b-4e79-bf62-cc3a391ded23",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_icl_prompt = '''\n",
    "    Answer the following query in detail with explanations.\n",
    "    \n",
    "    Query: \"{EX_QUERY}\"\n",
    "    Answer: \"{EX_ANSWER}\"\n",
    "\n",
    "    Query: \"{QUERY}\"\n",
    "    Answer:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6d641-cff3-4479-afc4-797ac5781ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "GENERATE USING ICL EXAMPLES\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b89c7b-c7f2-4a92-9b29-92848aae1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_num = 0\n",
    "\n",
    "for index,row in tqdm(icl_data.iterrows(), total=icl_data.shape[0]):\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    ex_query = row['query']\n",
    "    ex_answer = row['text']\n",
    "    prompt = template_icl_prompt.format(EX_QUERY=ex_query, EX_ANSWER=ex_answer, QUERY=query)\n",
    "    gen_text = LLMGenerator.generate(model_name,parameters, prompt, gen_mode = True)\n",
    "    if model_name=='zephyr':\n",
    "        llm_output = gen_text.split('\\n')\n",
    "        icl_data.loc[index, 'llm_text'] = llm_output[len(llm_output)-1]\n",
    "    else:\n",
    "        icl_data.loc[index, 'llm_text'] = gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39e694-cbe9-4bc1-aafe-4bd0daf822a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "EVALUATE THE GENERATED OUTPUT\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a5d4f-1beb-4216-a3ba-595495a438b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in tqdm(icl_data.iterrows(), total=icl_data.shape[0]):\n",
    "    text = row['text']\n",
    "    llm_text = row['llm_text']\n",
    "    \n",
    "    embedding_text = model.encode(text)\n",
    "    embedding_llm_text = model.encode(llm_text)\n",
    "    \n",
    "    sim_score = util.pytorch_cos_sim(embedding_text, embedding_llm_text)\n",
    "    sim_score = sim_score.tolist()\n",
    "    sim_score = sim_score[0]\n",
    "\n",
    "    icl_data.loc[index, 'sim_score'] = sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d431d-1b84-4515-85e8-37448b6307c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptr",
   "language": "python",
   "name": "gptr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
